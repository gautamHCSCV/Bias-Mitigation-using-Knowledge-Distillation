{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1180c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0d075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33917e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  6 22:55:46 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.84       Driver Version: 460.84       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 24%   57C    P2    70W / 250W |   5517MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 20%   26C    P8     7W / 250W |    265MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 20%   44C    P2    56W / 250W |   3186MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 20%   24C    P8     7W / 250W |    265MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 20%   30C    P8     7W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 20%   30C    P0    58W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 20%   26C    P8     7W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 20%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16588      C   python3                           649MiB |\n",
      "|    0   N/A  N/A     29399      C   python3                          4417MiB |\n",
      "|    0   N/A  N/A     38504      C   /opt/conda/bin/python             445MiB |\n",
      "|    1   N/A  N/A     29399      C   python3                           261MiB |\n",
      "|    2   N/A  N/A     14515      C   python3                          2919MiB |\n",
      "|    2   N/A  N/A     29399      C   python3                           261MiB |\n",
      "|    3   N/A  N/A     29399      C   python3                           261MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c5d978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b34f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    saved_path=\"saved_models/random.pt\",\n",
    "    best_saved_path = \"saved/random_best.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 3,\n",
    "    BATCH_SIZE = 32,\n",
    "    IMAGE_SIZE = 224,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "    device=device,\n",
    "    SEED = 42,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    USE_AMP = True,\n",
    "    channels_last=False)\n",
    "\n",
    "random.seed(config['SEED'])\n",
    "# If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG \n",
    "np.random.seed(config['SEED'])\n",
    "# Prevent RNG for CPU and GPU using torch\n",
    "torch.manual_seed(config['SEED'])\n",
    "torch.cuda.manual_seed(config['SEED'])\n",
    "torch.backends.cudnn.benchmarks = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad58a2",
   "metadata": {},
   "source": [
    "# DATA method (Pre-Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ed08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6547e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data = torchvision.datasets.CIFAR10(root='../Images', train=True, download=True, transform=data_transforms['train'])\n",
    "test_data = torchvision.datasets.CIFAR10(root='../Images', train=False, download=True, transform=data_transforms['test'])\n",
    "valid_data = test_data\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "valid_dl = torch.utils.data.DataLoader(valid_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe7c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,num_epochs=10):\n",
    "\n",
    "    since = time.time()                                            \n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    best_acc = 0.3\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        run_corrects = 0\n",
    "        #Training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])            \n",
    "            if config['channels_last']:\n",
    "                x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
    "            else:\n",
    "                x = x.to(config['device'])\n",
    "            y = y.to(config['device']) #CHW --> #HWC\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #optimizer.zero_grad(set_to_none=True)\n",
    "            ######################################################################\n",
    "            \n",
    "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
    "            \n",
    "            _, train_preds = torch.max(train_logits, 1)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            run_corrects += torch.sum(train_preds == y.data)\n",
    "            \n",
    "            train_loss.backward() # Backpropagation this is where your W_gradient\n",
    "            loss=train_loss\n",
    "\n",
    "            optimizer.step() # W_new = W_old - LR * W_gradient \n",
    "            example_ct += len(x) \n",
    "            batch_ct += 1\n",
    "            if ((batch_ct + 1) % 400) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            ########################################################################\n",
    "        \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "        with torch.no_grad():\n",
    "            for x,y in valid_dl:\n",
    "                if config['channels_last']:\n",
    "                    x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
    "                else:\n",
    "                    x = x.to(config['device'])\n",
    "                y = y.to(config['device'])\n",
    "                valid_logits = model(x)\n",
    "                _, valid_preds = torch.max(valid_logits, 1)\n",
    "                valid_loss = criterion(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / len(valid_data)\n",
    "        epoch_acc = running_corrects.double() / len(valid_data)\n",
    "        train_acc = run_corrects.double() / len(train_data)\n",
    "        print(\"Train Accuracy\",train_acc.cpu())\n",
    "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
    "        print(\"Validation Accuracy is {}\\n\".format(epoch_acc.cpu()))\n",
    "        if epoch_acc.cpu()>best_acc:\n",
    "            print('One of the best validation accuracy found.\\n')\n",
    "            #torch.save(model.state_dict(), config['best_saved_path'])\n",
    "            best_acc = epoch_acc.cpu()\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    torch.save(model.state_dict(), config['saved_path'])\n",
    "\n",
    "    \n",
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63667a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/7\n",
      "----------\n",
      "Loss after 12768 examples: 0.472\n",
      "Loss after 25568 examples: 0.265\n",
      "Loss after 38368 examples: 0.423\n",
      "Train Accuracy tensor(0.8500, dtype=torch.float64)\n",
      "Validation Loss is 0.28712995879650116\n",
      "Validation Accuracy is 0.9034000000000001\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 1/7\n",
      "----------\n",
      "Loss after 51152 examples: 0.258\n",
      "Loss after 63952 examples: 0.161\n",
      "Loss after 76752 examples: 0.259\n",
      "Loss after 89552 examples: 0.498\n",
      "Train Accuracy tensor(0.9102, dtype=torch.float64)\n",
      "Validation Loss is 0.26927664377093313\n",
      "Validation Accuracy is 0.9115000000000001\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 2/7\n",
      "----------\n",
      "Loss after 102336 examples: 0.178\n",
      "Loss after 115136 examples: 0.045\n",
      "Loss after 127936 examples: 0.186\n",
      "Loss after 140736 examples: 0.223\n",
      "Train Accuracy tensor(0.9283, dtype=torch.float64)\n",
      "Validation Loss is 0.21797222988158466\n",
      "Validation Accuracy is 0.9293\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 3/7\n",
      "----------\n",
      "Loss after 153520 examples: 0.084\n",
      "Loss after 166320 examples: 0.116\n",
      "Loss after 179120 examples: 0.178\n",
      "Loss after 191920 examples: 0.036\n",
      "Train Accuracy tensor(0.9404, dtype=torch.float64)\n",
      "Validation Loss is 0.24270267499610781\n",
      "Validation Accuracy is 0.9273\n",
      "\n",
      "Epoch 4/7\n",
      "----------\n",
      "Loss after 204704 examples: 0.064\n",
      "Loss after 217504 examples: 0.096\n",
      "Loss after 230304 examples: 0.204\n",
      "Loss after 243104 examples: 0.204\n",
      "Train Accuracy tensor(0.9497, dtype=torch.float64)\n",
      "Validation Loss is 0.22769008892253043\n",
      "Validation Accuracy is 0.9276000000000001\n",
      "\n",
      "Epoch 5/7\n",
      "----------\n",
      "Loss after 255888 examples: 0.137\n",
      "Loss after 268688 examples: 0.122\n",
      "Loss after 281488 examples: 0.190\n",
      "Loss after 294288 examples: 0.459\n",
      "Train Accuracy tensor(0.9559, dtype=torch.float64)\n",
      "Validation Loss is 0.2184410038024187\n",
      "Validation Accuracy is 0.9333\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 6/7\n",
      "----------\n",
      "Loss after 307072 examples: 0.160\n",
      "Loss after 319872 examples: 0.087\n",
      "Loss after 332672 examples: 0.304\n",
      "Loss after 345472 examples: 0.080\n",
      "Train Accuracy tensor(0.9615, dtype=torch.float64)\n",
      "Validation Loss is 0.24787979627251625\n",
      "Validation Accuracy is 0.9263\n",
      "\n",
      "Epoch 7/7\n",
      "----------\n",
      "Loss after 358256 examples: 0.013\n",
      "Loss after 371056 examples: 0.009\n",
      "Loss after 383856 examples: 0.082\n",
      "Loss after 396656 examples: 0.301\n",
      "Train Accuracy tensor(0.9661, dtype=torch.float64)\n",
      "Validation Loss is 0.23503911791406573\n",
      "Validation Accuracy is 0.9334\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Training complete in 32m 0s\n"
     ]
    }
   ],
   "source": [
    "efficientnet = models.efficientnet_b0(pretrained = True)\n",
    "efficientnet.classifier[1] = nn.Linear(in_features = 1280, out_features = 10, bias = True)\n",
    "model = efficientnet\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(config['device'])\n",
    "optimizer = optim.Adam(model.parameters(),lr=config['lr'])\n",
    "#model.load_state_dict(torch.load('saved_models/child.pt'))\n",
    "train_model(model,criterion,optimizer,num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11ec20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet = models.efficientnet_b0(pretrained = True)\n",
    "efficientnet.classifier[1] = nn.Linear(in_features = 1280, out_features = 10, bias = True)\n",
    "model = efficientnet\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(config['device'])\n",
    "optimizer = optim.Adam(model.parameters(),lr=config['lr'])\n",
    "model.load_state_dict(torch.load('saved_models/random.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167403c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.23503911691755056\n",
      "Test Accuracy is 0.9334\n",
      "\n",
      "AUROC:\n",
      "0.9970546777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1000\n",
      "           1       0.95      0.97      0.96      1000\n",
      "           2       0.93      0.90      0.92      1000\n",
      "           3       0.90      0.82      0.86      1000\n",
      "           4       0.96      0.93      0.94      1000\n",
      "           5       0.87      0.91      0.89      1000\n",
      "           6       0.92      0.97      0.94      1000\n",
      "           7       0.96      0.97      0.97      1000\n",
      "           8       0.97      0.96      0.96      1000\n",
      "           9       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model,test_dl):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "                for x,y in test_dl:\n",
    "                    x = x.to(config['device'])\n",
    "                    y = y.to(config['device']) #CHW --> #HWC\n",
    "                    valid_logits = model(x)\n",
    "                    predict_prob = F.softmax(valid_logits)\n",
    "                    _,predictions = predict_prob.max(1)\n",
    "                    predictions = predictions.to('cpu')\n",
    "\n",
    "                    _, valid_preds = torch.max(valid_logits, 1)\n",
    "                    valid_loss = criterion(valid_logits,y)\n",
    "                    running_loss += valid_loss.item() * x.size(0)\n",
    "                    running_corrects += torch.sum(valid_preds == y.data)\n",
    "                    total += y.size(0)\n",
    "                    predict_prob = predict_prob.to('cpu')\n",
    "\n",
    "                    pred_labels.extend(list(predictions.numpy()))\n",
    "                    preds.extend(list(predict_prob.numpy()))\n",
    "                    y = y.to('cpu')\n",
    "                    labels.extend(list(y.numpy()))\n",
    "\n",
    "    epoch_loss = running_loss / len(test_data)\n",
    "    epoch_acc = running_corrects.double() / len(test_data)\n",
    "    print(\"Test Loss is {}\".format(epoch_loss))\n",
    "    print(\"Test Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "    return np.array(labels),np.array(pred_labels),np.array(preds)\n",
    "    \n",
    "\n",
    "labels, pred_labels,preds = evaluation(model, test_dl)\n",
    "#print(metrics.precision_recall_fscore_support(np.array(labels), np.array(pred_labels)))\n",
    "print('\\nAUROC:')\n",
    "print(metrics.roc_auc_score(np.array(labels), np.array(preds), multi_class='ovr'))\n",
    "print(metrics.classification_report(labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bbdc68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.9573\n"
     ]
    }
   ],
   "source": [
    "def calculate_disparate_impact(model, dataloader):\n",
    "    #device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_counts = torch.zeros((10,))\n",
    "        correct_counts = torch.zeros((10,))\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            for i in range(10):\n",
    "                class_mask = labels == i\n",
    "                class_counts[i] += torch.sum(class_mask)\n",
    "                correct_counts[i] += torch.sum(preds[class_mask] == labels[class_mask])\n",
    "\n",
    "        proportions = correct_counts / class_counts\n",
    "        reference_proportion = torch.mean(proportions)\n",
    "        max_proportion = torch.max(proportions)\n",
    "        \n",
    "        return reference_proportion / max_proportion\n",
    "    \n",
    "device = 'cpu'\n",
    "model = model.to('cpu')\n",
    "disparate_impact = calculate_disparate_impact(model, test_dl)\n",
    "print(f\"Disparate Impact: {disparate_impact:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdb0b6",
   "metadata": {},
   "source": [
    "# ALGORITHMIC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422c8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/7\n",
      "----------\n",
      "Loss after 12768 examples: 0.695\n",
      "Loss after 25568 examples: 0.564\n",
      "Loss after 38368 examples: 0.446\n",
      "Train Accuracy tensor(0.8496, dtype=torch.float64)\n",
      "Validation Loss is 0.2618277025580406\n",
      "Validation Accuracy is 0.9157000000000001\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 1/7\n",
      "----------\n",
      "Loss after 51152 examples: 0.147\n",
      "Loss after 63952 examples: 0.244\n",
      "Loss after 76752 examples: 0.176\n",
      "Loss after 89552 examples: 0.076\n",
      "Train Accuracy tensor(0.9090, dtype=torch.float64)\n",
      "Validation Loss is 0.2631435434222221\n",
      "Validation Accuracy is 0.9158000000000001\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 2/7\n",
      "----------\n",
      "Loss after 102336 examples: 0.044\n",
      "Loss after 115136 examples: 0.248\n",
      "Loss after 127936 examples: 0.026\n",
      "Loss after 140736 examples: 0.260\n",
      "Train Accuracy tensor(0.9266, dtype=torch.float64)\n",
      "Validation Loss is 0.2133455213084817\n",
      "Validation Accuracy is 0.9285\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 3/7\n",
      "----------\n",
      "Loss after 153520 examples: 0.059\n",
      "Loss after 166320 examples: 0.175\n",
      "Loss after 179120 examples: 0.347\n",
      "Loss after 191920 examples: 0.059\n",
      "Train Accuracy tensor(0.9411, dtype=torch.float64)\n",
      "Validation Loss is 0.23835473617613315\n",
      "Validation Accuracy is 0.9242\n",
      "\n",
      "Epoch 4/7\n",
      "----------\n",
      "Loss after 204704 examples: 0.216\n",
      "Loss after 217504 examples: 0.082\n",
      "Loss after 230304 examples: 0.184\n",
      "Loss after 243104 examples: 0.202\n",
      "Train Accuracy tensor(0.9466, dtype=torch.float64)\n",
      "Validation Loss is 0.210179260379076\n",
      "Validation Accuracy is 0.9335\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 5/7\n",
      "----------\n",
      "Loss after 255888 examples: 0.390\n",
      "Loss after 268688 examples: 0.412\n",
      "Loss after 281488 examples: 0.204\n",
      "Loss after 294288 examples: 0.186\n",
      "Train Accuracy tensor(0.9572, dtype=torch.float64)\n",
      "Validation Loss is 0.21933484842926262\n",
      "Validation Accuracy is 0.9342\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 6/7\n",
      "----------\n",
      "Loss after 307072 examples: 0.167\n",
      "Loss after 319872 examples: 0.017\n",
      "Loss after 332672 examples: 0.026\n",
      "Loss after 345472 examples: 0.112\n",
      "Train Accuracy tensor(0.9615, dtype=torch.float64)\n",
      "Validation Loss is 0.23769259917885066\n",
      "Validation Accuracy is 0.9283\n",
      "\n",
      "Epoch 7/7\n",
      "----------\n",
      "Loss after 358256 examples: 0.074\n",
      "Loss after 371056 examples: 0.013\n",
      "Loss after 383856 examples: 0.038\n",
      "Loss after 396656 examples: 0.117\n",
      "Train Accuracy tensor(0.9652, dtype=torch.float64)\n",
      "Validation Loss is 0.2320513121932745\n",
      "Validation Accuracy is 0.9345\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Training complete in 30m 54s\n"
     ]
    }
   ],
   "source": [
    "class ReweightedCELoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes, device):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.class_counts = torch.zeros((self.num_classes,)).to(self.device)\n",
    "        self.loss_weights = torch.ones((self.num_classes,)).to(self.device)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        batch_size = logits.size(0)\n",
    "\n",
    "        # Compute standard cross-entropy loss\n",
    "        loss_ce = F.cross_entropy(logits, labels)\n",
    "\n",
    "        # Update class counts and loss weights\n",
    "        class_counts_batch = torch.zeros((self.num_classes,)).to(self.device)\n",
    "        for i in range(batch_size):\n",
    "            class_counts_batch[labels[i]] += 1\n",
    "        self.class_counts += class_counts_batch\n",
    "        self.loss_weights = 1 / torch.sqrt(self.class_counts)\n",
    "\n",
    "        # Compute re-weighted loss\n",
    "        loss_rce = 0\n",
    "        for c in range(self.num_classes):\n",
    "            mask_c = labels == c\n",
    "            if torch.sum(mask_c) == 0:\n",
    "                continue\n",
    "            logits_c = logits[:, c]\n",
    "            loss_weights_c = self.loss_weights[c]\n",
    "            loss_rce += torch.mean(loss_weights_c * F.binary_cross_entropy_with_logits(logits_c, mask_c.float()))\n",
    "\n",
    "        return loss_ce + loss_rce\n",
    "\n",
    "criterion = ReweightedCELoss(num_classes=10, device=device)\n",
    "\n",
    "efficientnet = models.efficientnet_b0(pretrained = True)\n",
    "efficientnet.classifier[1] = nn.Linear(in_features = 1280, out_features = 10, bias = True)\n",
    "model = efficientnet\n",
    "model = model.to(config['device'])\n",
    "optimizer = optim.Adam(model.parameters(),lr=config['lr'])\n",
    "train_model(model,criterion,optimizer,num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e88eec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.23201741560399533\n",
      "Test Accuracy is 0.9345\n",
      "\n",
      "AUROC:\n",
      "0.9968824833333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1000\n",
      "           1       0.98      0.94      0.96      1000\n",
      "           2       0.93      0.91      0.92      1000\n",
      "           3       0.89      0.84      0.87      1000\n",
      "           4       0.91      0.95      0.93      1000\n",
      "           5       0.92      0.90      0.91      1000\n",
      "           6       0.95      0.96      0.95      1000\n",
      "           7       0.97      0.96      0.97      1000\n",
      "           8       0.96      0.95      0.96      1000\n",
      "           9       0.93      0.98      0.95      1000\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model,test_dl):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "                for x,y in test_dl:\n",
    "                    x = x.to(config['device'])\n",
    "                    y = y.to(config['device']) #CHW --> #HWC\n",
    "                    valid_logits = model(x)\n",
    "                    predict_prob = F.softmax(valid_logits)\n",
    "                    _,predictions = predict_prob.max(1)\n",
    "                    predictions = predictions.to('cpu')\n",
    "\n",
    "                    _, valid_preds = torch.max(valid_logits, 1)\n",
    "                    valid_loss = criterion(valid_logits,y)\n",
    "                    running_loss += valid_loss.item() * x.size(0)\n",
    "                    running_corrects += torch.sum(valid_preds == y.data)\n",
    "                    total += y.size(0)\n",
    "                    predict_prob = predict_prob.to('cpu')\n",
    "\n",
    "                    pred_labels.extend(list(predictions.numpy()))\n",
    "                    preds.extend(list(predict_prob.numpy()))\n",
    "                    y = y.to('cpu')\n",
    "                    labels.extend(list(y.numpy()))\n",
    "\n",
    "    epoch_loss = running_loss / len(test_data)\n",
    "    epoch_acc = running_corrects.double() / len(test_data)\n",
    "    print(\"Test Loss is {}\".format(epoch_loss))\n",
    "    print(\"Test Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "    return np.array(labels),np.array(pred_labels),np.array(preds)\n",
    "    \n",
    "\n",
    "labels, pred_labels,preds = evaluation(model, test_dl)\n",
    "#print(metrics.precision_recall_fscore_support(np.array(labels), np.array(pred_labels)))\n",
    "print('\\nAUROC:')\n",
    "print(metrics.roc_auc_score(np.array(labels), np.array(preds), multi_class='ovr'))\n",
    "print(metrics.classification_report(labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7821097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.9565\n"
     ]
    }
   ],
   "source": [
    "def calculate_disparate_impact(model, dataloader):\n",
    "    #device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_counts = torch.zeros((10,))\n",
    "        correct_counts = torch.zeros((10,))\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            for i in range(10):\n",
    "                class_mask = labels == i\n",
    "                class_counts[i] += torch.sum(class_mask)\n",
    "                correct_counts[i] += torch.sum(preds[class_mask] == labels[class_mask])\n",
    "\n",
    "        proportions = correct_counts / class_counts\n",
    "        reference_proportion = torch.mean(proportions)\n",
    "        max_proportion = torch.max(proportions)\n",
    "        return reference_proportion / max_proportion\n",
    "    \n",
    "device = 'cpu'\n",
    "model = model.to('cpu')\n",
    "disparate_impact = calculate_disparate_impact(model, test_dl)\n",
    "print(f\"Disparate Impact: {disparate_impact:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8600bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
